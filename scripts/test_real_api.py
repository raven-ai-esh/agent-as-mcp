"""Integration test with real OpenAI API + Ollama embeddings.

Usage:
    1. Create .env file with OPENAI_API_KEY=sk-...
    2. Make sure Ollama is running with bge-m3 model
    3. Run: python scripts/test_real_api.py
"""

import asyncio
import os
import sys

# Add project root to path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from dotenv import load_dotenv
load_dotenv()

from openai import AsyncOpenAI
from raven_skills import SkillAgent, SkillStorage, Skill
from raven_skills.utils.similarity import cosine_similarity


class InMemoryStorage(SkillStorage):
    """Simple in-memory storage for testing."""
    
    def __init__(self):
        self._skills: dict[str, Skill] = {}
    
    async def save(self, skill: Skill) -> None:
        self._skills[skill.id] = skill
        print(f"  üíæ Saved skill: {skill.name} (id={skill.id[:8]}...)")
    
    async def get(self, skill_id: str) -> Skill | None:
        return self._skills.get(skill_id)
    
    async def get_all(self) -> list[Skill]:
        return list(self._skills.values())
    
    async def delete(self, skill_id: str) -> None:
        self._skills.pop(skill_id, None)
    
    async def search_by_embedding(
        self,
        embedding: list[float],
        top_k: int = 5,
        min_score: float = 0.0,
    ) -> list[tuple[Skill, float]]:
        results = []
        for skill in self._skills.values():
            if skill.metadata.embedding:
                score = cosine_similarity(embedding, skill.metadata.embedding)
                if score >= min_score:
                    results.append((skill, score))
        results.sort(key=lambda x: x[1], reverse=True)
        return results[:top_k]


async def test_skill_generation(agent: SkillAgent):
    """Test generating a skill from conversation."""
    print("\n" + "="*60)
    print("üß™ TEST 1: Skill Generation")
    print("="*60)
    
    # Prepare a task
    print("\nüìù Preparing task...")
    task = await agent.prepare_task("–ö–∞–∫ –∑–∞–¥–µ–ø–ª–æ–∏—Ç—å Python –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –≤ Docker?")
    print(f"  Query: {task.query}")
    print(f"  Key aspects: {task.key_aspects}")
    print(f"  Embedding dims: {len(task.embedding)}")
    
    # Simulate a conversation
    conversation = [
        {"role": "user", "content": "–ö–∞–∫ –∑–∞–¥–µ–ø–ª–æ–∏—Ç—å Python –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –≤ Docker?"},
        {"role": "assistant", "content": "–î–ª—è –¥–µ–ø–ª–æ—è Python –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –≤ Docker –Ω—É–∂–Ω–æ:\n1. –°–æ–∑–¥–∞—Ç—å Dockerfile\n2. –°–æ–±—Ä–∞—Ç—å –æ–±—Ä–∞–∑\n3. –ó–∞–ø—É—Å—Ç–∏—Ç—å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä"},
        {"role": "user", "content": "–ê –∫–∞–∫ –Ω–∞–ø–∏—Å–∞—Ç—å Dockerfile?"},
        {"role": "assistant", "content": "–í–æ—Ç –ø—Ä–∏–º–µ—Ä Dockerfile:\n\nFROM python:3.11-slim\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\nCOPY . .\nCMD [\"python\", \"main.py\"]"},
    ]
    
    # Generate skill
    print("\nüîß Generating skill from conversation...")
    skill = await agent.generate_skill(
        task=task,
        conversation=conversation,
        final_result="–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–ø—É—â–µ–Ω–æ –≤ Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ",
    )
    
    print(f"\n‚úÖ Generated skill:")
    print(f"  Name: {skill.name}")
    print(f"  Description: {skill.metadata.description}")
    print(f"  Goal: {skill.metadata.goal}")
    print(f"  Keywords: {skill.metadata.keywords}")
    print(f"  Embedding dims: {len(skill.metadata.embedding)}")
    print(f"  Steps ({len(skill.steps)}):")
    for step in skill.steps:
        print(f"    {step.order}. {step.instruction}")
    
    return skill


async def test_skill_matching(agent: SkillAgent, skill: Skill):
    """Test matching a query to existing skills."""
    print("\n" + "="*60)
    print("üß™ TEST 2: Skill Matching")
    print("="*60)
    
    # Try to match a similar query
    print("\nüîç Matching query: '–î–µ–ø–ª–æ–π –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä'")
    task, result = await agent.match("–î–µ–ø–ª–æ–π –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä")
    
    print(f"\nüìä Match result:")
    print(f"  Found: {result.found}")
    print(f"  Score: {result.score:.4f}")
    print(f"  Threshold passed: {result.threshold_passed}")
    
    if result.skill:
        print(f"  Matched skill: {result.skill.name}")
    
    # Try a very different query
    print("\nüîç Matching query: '–ö–∞–∫ –ø—Ä–∏–≥–æ—Ç–æ–≤–∏—Ç—å –±–æ—Ä—â'")
    task2, result2 = await agent.match("–ö–∞–∫ –ø—Ä–∏–≥–æ—Ç–æ–≤–∏—Ç—å –±–æ—Ä—â")
    
    print(f"\nüìä Match result:")
    print(f"  Found: {result2.found}")
    print(f"  Score: {result2.score:.4f}")
    
    return result


async def test_skill_execution(agent: SkillAgent, skill: Skill):
    """Test executing a skill."""
    print("\n" + "="*60)
    print("üß™ TEST 3: Skill Execution")
    print("="*60)
    
    task = await agent.prepare_task("–•–æ—á—É –∑–∞–¥–µ–ø–ª–æ–∏—Ç—å —Å–≤–æ–π Flask —Å–µ—Ä–≤–µ—Ä")
    
    print(f"\n‚ö° Executing skill: {skill.name}")
    print(f"   Steps to execute: {len(skill.steps)}")
    
    result = await agent.execute(skill, task)
    
    print(f"\nüìä Execution result:")
    print(f"  Success: {result.success}")
    print(f"  Steps completed: {len(result.steps_completed)}")
    
    if result.output:
        output_preview = result.output[:300] + "..." if len(result.output) > 300 else result.output
        print(f"  Output: {output_preview}")
    
    if result.error:
        print(f"  Error: {result.error}")
    
    return result


async def test_diagnosis(agent: SkillAgent, skill: Skill, task, exec_result):
    """Test diagnosis and refinement."""
    print("\n" + "="*60)
    print("üß™ TEST 4: Diagnosis & Refinement")
    print("="*60)
    
    print("\nüî¨ Diagnosing execution...")
    action = await agent.diagnose(
        skill=skill,
        task=task,
        result=exec_result,
        user_feedback="–ù—É–∂–Ω–æ –±–æ–ª—å—à–µ –¥–µ—Ç–∞–ª–µ–π –ø—Ä–æ docker-compose",
    )
    
    print(f"\nüìä Diagnosis result:")
    print(f"  Type: {action.type}")
    print(f"  Diagnosis: {action.diagnosis}")
    print(f"  Suggested changes: {action.suggested_changes}")
    
    print("\nüîß Refining skill...")
    refined = await agent.refine(skill, action)
    
    print(f"\n‚úÖ Refined skill:")
    print(f"  Name: {refined.name}")
    print(f"  Version: {refined.version}")
    print(f"  Steps ({len(refined.steps)}):")
    for step in refined.steps[:3]:  # Show first 3 steps
        print(f"    {step.order}. {step.instruction}")
    if len(refined.steps) > 3:
        print(f"    ... and {len(refined.steps) - 3} more steps")


async def main():
    print("\n" + "üöÄ"*30)
    print("  raven-skills Integration Test")
    print("  OpenAI (LLM) + Ollama (Embeddings)")
    print("üöÄ"*30)
    
    # Check API key
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("\n‚ùå Error: OPENAI_API_KEY not found in environment")
        print("   Please create .env file with your API key")
        return
    
    print(f"\n‚úÖ OpenAI API key: {api_key[:15]}...")
    print("‚úÖ Ollama embeddings: http://localhost:11434/v1")
    
    # Create clients
    llm_client = AsyncOpenAI()
    embedding_client = AsyncOpenAI(
        base_url="http://localhost:11434/v1",
        api_key="ollama",
    )
    
    # Create agent
    storage = InMemoryStorage()
    agent = SkillAgent(
        client=llm_client,
        embedding_client=embedding_client,
        storage=storage,
        llm_model="gpt-4o-mini",
        embedding_model="bge-m3:latest",
        similarity_threshold=0.6,  # Lower threshold for testing
        validate_matches=False,  # Skip LLM validation for speed
    )
    
    print("\n‚úÖ SkillAgent initialized")
    
    try:
        # Run tests
        skill = await test_skill_generation(agent)
        result = await test_skill_matching(agent, skill)
        
        task = await agent.prepare_task("–•–æ—á—É –∑–∞–¥–µ–ø–ª–æ–∏—Ç—å Flask")
        exec_result = await test_skill_execution(agent, skill)
        
        await test_diagnosis(agent, skill, task, exec_result)
        
        print("\n" + "="*60)
        print("‚úÖ ALL TESTS COMPLETED SUCCESSFULLY!")
        print("="*60 + "\n")
        
    except Exception as e:
        print(f"\n‚ùå Test failed with error: {e}")
        import traceback
        traceback.print_exc()
        raise


if __name__ == "__main__":
    asyncio.run(main())
